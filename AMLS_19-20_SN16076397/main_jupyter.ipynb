{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.svm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import landmarks\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "* write a generic function which imports all images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A1\n",
    "Gender detection: male or female.\n",
    "\n",
    "Import raw data.\n",
    "\n",
    "### TODO:\n",
    "* function for doing what landmarks is currently doing\n",
    "\n",
    "Flow:\n",
    "* import all images and labels\n",
    "* plot a few examples to make sure it's imported well\n",
    "* split into train, validation, test sets\n",
    "* try a few approaches:\n",
    "  * use dlib to extract the landmarks, plot overlayed:\n",
    "    * use a few shallow learning algos and compare, do hyperparameter optimization for each\n",
    "  * use CNN\n",
    "  * use pretrained keras model\n",
    "* test on the test set using the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a1_X_train_raw, a1_y_train_raw = landmarks.extract_features_labels(\"celeba\")\n",
    "a1_X_test_raw, a1_y_test_raw = landmarks.extract_features_labels(\"celeba_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert raw data into Pandas DataFrames, then split train set into train set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender == 0 means female\n",
    "a1_X_labels = np.array([(f\"x_{i}\", f\"y_{i}\") for i in range(68)]).flatten()\n",
    "\n",
    "a1_X_train = pd.DataFrame(data=a1_X_train_raw.reshape(a1_X_train_raw.shape[0], -1), columns=a1_X_labels)\n",
    "a1_y_train = pd.DataFrame(data=a1_y_train_raw, columns=[\"image_name\", \"gender\", \"smiling\"])\n",
    "\n",
    "a1_X_train, a1_X_validation, a1_y_train, a1_y_validation = sklearn.model_selection.train_test_split(a1_X_train, a1_y_train, train_size=0.75)\n",
    "\n",
    "a1_X_test = pd.DataFrame(data=a1_X_test_raw.reshape(a1_X_test_raw.shape[0], -1), columns=a1_X_labels)\n",
    "a1_y_test = pd.DataFrame(data=a1_y_test_raw, columns=[\"image_name\", \"gender\", \"smiling\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_model = sklearn.svm.SVC(kernel=\"linear\")\n",
    "\n",
    "a1_model.fit(a1_X_train, a1_y_train[\"gender\"])\n",
    "\n",
    "sklearn.metrics.accuracy_score(a1_y_validation[\"gender\"], a1_model.predict(a1_X_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task A2\n",
    "Emotion detection: smiling or not smiling.\n",
    "\n",
    "Import raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a2_X_train_raw, a2_y_train_raw = landmarks.extract_features_labels(\"celeba\")\n",
    "a2_X_test_raw, a2_y_test_raw = landmarks.extract_features_labels(\"celeba_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert raw data into Pandas DataFrames, then split train set into train set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender == 0 means female\n",
    "a2_X_labels = np.array([(f\"x_{i}\", f\"y_{i}\") for i in range(68)]).flatten()\n",
    "\n",
    "a2_X_train = pd.DataFrame(data=a2_X_train_raw.reshape(a2_X_train_raw.shape[0], -1), columns=a2_X_labels)\n",
    "a2_y_train = pd.DataFrame(data=a2_y_train_raw, columns=[\"image_name\", \"gender\", \"smiling\"])\n",
    "\n",
    "a2_X_train, a2_X_validation, a2_y_train, a2_y_validation = sklearn.model_selection.train_test_split(a2_X_train, a2_y_train, train_size=0.75)\n",
    "\n",
    "a2_X_test = pd.DataFrame(data=a2_X_test_raw.reshape(a2_X_test_raw.shape[0], -1), columns=a2_X_labels)\n",
    "a2_y_test = pd.DataFrame(data=a2_y_test_raw, columns=[\"image_name\", \"gender\", \"smiling\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2_model = sklearn.svm.SVC(kernel=\"linear\")\n",
    "\n",
    "a2_model.fit(a2_X_train, a2_y_train[\"gender\"])\n",
    "\n",
    "sklearn.metrics.accuracy_score(a2_y_validation[\"gender\"], a2_model.predict(a2_X_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B1\n",
    "Face shape recognition: 5 types of face shapes\n",
    "\n",
    "Import raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b1_X_train_raw, b1_y_train_raw = landmarks.extract_features_labels(\"cartoon_set\")\n",
    "b1_X_test_raw, b1_y_test_raw = landmarks.extract_features_labels(\"cartoon_set_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert raw data into Pandas DataFrames, then split train set into train set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_X_labels = np.array([(f\"x_{i}\", f\"y_{i}\") for i in range(68)]).flatten()\n",
    "\n",
    "b1_X_train = pd.DataFrame(data=b1_X_train_raw.reshape(b1_X_train_raw.shape[0], -1), columns=b1_X_labels)\n",
    "b1_y_train = pd.DataFrame(data=b1_y_train_raw, columns=[\"eye_color\", \"face_shape\", \"file_name\"])\n",
    "\n",
    "b1_X_train, b1_X_validation, b1_y_train, b1_y_validation = sklearn.model_selection.train_test_split(b1_X_train, b1_y_train, train_size=0.75)\n",
    "\n",
    "b1_X_test = pd.DataFrame(data=b1_X_test_raw.reshape(b1_X_test_raw.shape[0], -1), columns=b1_X_labels)\n",
    "b1_y_test = pd.DataFrame(data=b1_y_test_raw, columns=[\"eye_color\", \"face_shape\", \"file_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_model = sklearn.svm.SVC(kernel=\"linear\")\n",
    "\n",
    "b1_model.fit(b1_X_train, b1_y_train[\"face_shape\"])\n",
    "\n",
    "sklearn.metrics.accuracy_score(b1_y_validation[\"face_shape\"], b1_model.predict(b1_X_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B2\n",
    "Eye color recognition: 5 types of eye colors\n",
    "\n",
    "eye color label:<br>\n",
    "0 - brown,<br>\n",
    "1 - blue,<br>\n",
    "2 - green,<br>\n",
    "3 - bright green,<br>\n",
    "4 - black.\n",
    "\n",
    "We'll use CNNs here.\n",
    "\n",
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(images_dirname):\n",
    "    # get paths of images\n",
    "    images_dir = os.path.join(\"./Datasets\", images_dirname, \"img\")\n",
    "    image_paths = sorted([os.path.join(images_dir, l) for l in os.listdir(images_dir)], key=lambda x: int(x.split(\".\")[1].split(\"/\")[-1]))\n",
    "    image_paths = image_paths[:1000] # TODO: remove\n",
    "    \n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        image = tf.keras.preprocessing.image.img_to_array(\n",
    "            tf.keras.preprocessing.image.load_img(\n",
    "                image_path, target_size=None, interpolation=\"bicubic\"\n",
    "            )\n",
    "        )\n",
    "        images.append(image)\n",
    "    images = np.array(images, dtype=int)\n",
    "\n",
    "    # get labels\n",
    "    labels_file = open(os.path.join(\"./Datasets\", images_dirname, \"labels.csv\"), \"r\")\n",
    "    lines = labels_file.readlines()\n",
    "    labels_file.close()\n",
    "    labels = []\n",
    "    for line in lines[1:1001]:  # TODO: remove limit\n",
    "        line = line.split()\n",
    "        labels.append([int(line[1]), int(line[2]), line[3]])\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_X_train_raw, b2_y_train_raw = load_images_and_labels(\"cartoon_set\")\n",
    "b2_X_test_raw, b2_y_test_raw = load_images_and_labels(\"cartoon_set_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all pixel values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_X_train = b2_X_train_raw / 255.0\n",
    "b2_X_test = b2_X_test_raw / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some images to verify correct import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_color = {0: \"brown\", 1: \"blue\", 2: \"green\", 3: \"grey\", 4: \"black\"}\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(b2_X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(eye_color[int(b2_y_train_raw[i][0])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the convolutional base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(500, 500, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    b2_X_train,\n",
    "    np.array(b2_y_train_raw)[:, 0].astype(int),\n",
    "    epochs=10,\n",
    "    validation_data=(b2_X_test, np.array(b2_y_test_raw)[:, 0].astype(int)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 5 classes\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "my_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "my_model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "# my_model.fit_generator(...)\n",
    "\n",
    "# # at this point, the top layers are well trained and we can start fine-tuning\n",
    "# # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# # and train the remaining top layers.\n",
    "\n",
    "# # let's visualize layer names and layer indices to see how many layers\n",
    "# # we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name)\n",
    "\n",
    "# # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# # the first 249 layers and unfreeze the rest:\n",
    "# my_for layer in model.layers[:249]:\n",
    "#    layer.trainable = False\n",
    "# my_for layer in model.layers[249:]:\n",
    "#    layer.trainable = True\n",
    "\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# from keras.optimizers import SGD\n",
    "# my_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# # alongside the top Dense layers\n",
    "# my_model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = sklearn.preprocessing.LabelBinarizer()\n",
    "enc.fit(np.array(b2_y_test_raw)[:, 0].astype(int))\n",
    "enc.transform(np.array(b2_y_test_raw)[:, 0].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(b2_X_test, enc.transform(np.array(b2_y_test_raw)[:, 0].astype(int)), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = my_model.evaluate(b2_X_test[:100], enc.transform(np.array(b2_y_test_raw)[:, 0].astype(int))[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = my_model.predict(b2_X_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.CategoricalAccuracy() \n",
    "m.update_state(enc.transform(np.array(b2_y_test_raw)[:, 0].astype(int))[:100], logits)\n",
    "m.result().numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out your results with following format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"TA1:{},{};TA2:{},{};TB1:{},{};TB2:{},{};\".format(\n",
    "        acc_A1_train,\n",
    "        acc_A1_test,\n",
    "        acc_A2_train,\n",
    "        acc_A2_test,\n",
    "        acc_B1_train,\n",
    "        acc_B1_test,\n",
    "        acc_B2_train,\n",
    "        acc_B2_test,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
